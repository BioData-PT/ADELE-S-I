#!/bin/sh

set -u -e -x

myself=$0

# Default values for global options.
sda_config=s3cmd.conf		# --sda-config pathname
sda_key=crypt4gh_key.pub	# --sda-key pathname

# Other variables.
mq_host=localhost
mq_credentials=test:test

url_api=http://$mq_host:15672/api
url_exchanges=$url_api/exchanges/gdi/sda
url_queues=$url_api/queues/gdi

encrypt () {
	for pathname do
		shift
		case $pathname in
			*.c4gh)
				# Don't encrypt.
				;;
			*)
				# Encrypt if there's no encrypted
				# variant of the file.
				[ ! -f "$pathname.c4gh" ] && set -- "$@" "$pathname"
		esac
	done

	if [ "$#" -gt 0 ]; then
		sda-cli encrypt -key "$sda_key" "$@"
	fi
}

upload () {
	# Encrypt+upload using sda-cli.

	encrypt "$@"

	for pathname do
		shift
		pathname=${pathname%.c4gh}.c4gh
		set -- "$@" "$pathname"
	done

	sda-cli upload -config "$sda_config" "$@"
}

curl () {
	# Helper function that makes curl calls a bit shorter.
	command curl --silent \
		--request POST \
		--user "$mq_credentials" \
		--header "Content-Type: application/json" \
		"$@"
}

access_key () {
	# Parses the S3 configuration file and outputs the access key.
	sed	-e '/^access_key[[:blank:]]*=[[:blank:]]*/!d' \
		-e 's///' -e 's/[[:blank:]]*$//' -e 'q' \
		"$sda_config"
}

publish () {
	# Will read base64-encoded messages from standard input, one
	# per line, decode each message and publish it.  Any output is
	# explicitly discarded.

	while IFS= read -r message; do
		printf "%s\n" "$message" | base64 -d |
		curl --data @- "$url_exchanges/publish"
	done >/dev/null
}

get_messages () {
	# Retrieves the messages on the queue given by the 1st argument.
	# The remaining arguments are file paths that we filter the
	# messages with.  Any message that does not correspond to any
	# of the given file paths is requeued.  The remaining messages
	# are individually base64-encoded and outputted on the standard
	# output stream, one message per line of output.

	queue=$1
	shift

	access_key=$(access_key)

	for pathname do
		shift
		pathname=$access_key/$(basename "$pathname" .c4gh).c4gh
		set -- "$@" "$pathname"
	done

	tmpfile=$(mktemp)
	# shellcheck disable=SC2064
	trap "rm '$tmpfile'" EXIT

	# Get upload messages and ACK them all without requeuing them.
	# This empties the queue.
	#
	curl --data '{"count":-1,"encoding":"base64","ackmode":"ack_requeue_false"}' \
		"$url_queues/$queue/get" >"$tmpfile"

	# Requeue the messages that we're not interested in.
	#
	# Note that we only requeue unique messages, based on the file
	# path stored in the message payload.
	#
	jq -r 'JOIN(INDEX($ARGS.positional | unique[]; .);
		unique_by(.payload | @base64d | fromjson.filepath)[];
		.payload | @base64d | fromjson.filepath;
		if .[1] then empty else .[0] | @base64 end)' \
		--args "$@" <"$tmpfile" |
	publish

	# Filter out (extract) the the set of messages that we want to
	# keep.  This set does not contain any duplicated file paths.
	#
	jq -r 'JOIN(INDEX($ARGS.positional | unique[]; .);
		unique_by(.payload | @base64d | fromjson.filepath)[];
		.payload | @base64d | fromjson.filepath;
		if .[1] then .[0] | @base64 else empty end)' \
		--args "$@" <"$tmpfile"
}

get_filepaths () {
	queue=$1

	access_key=$(access_key)

	curl --data \
		'{"count":-1,"encoding":"base64","ackmode":"ack_requeue_true"}' \
		"$url_queues/$queue/get" |
	jq -r --arg access_key "$access_key" '
		map(.payload | @base64d | fromjson |
		select(.filepath | startswith($access_key + "/")).filepath |
			sub(".*?/"; "")) | unique[]'
}

ingest () {
	# Ingest named files.

	# If no arguments are given, list the files that may be
	# processed, then return immediately.
	#
	if [ "$#" -eq 0 ]; then
		get_filepaths inbox
		return
	fi

	# Get the messages that we want from the "inbox" queue, then
	# rewrite them into ingest messages and publish them.
	#
	get_messages inbox "$@" |
	jq -r -R '@base64d | fromjson |
		.payload |= (
			@base64d | fromjson |
			.type = "ingest" |
			del(.filesize,.operation) |
			tojson | @base64
		) |
		.routing_key = "ingest" |
		del(.payload_bytes) |
		@base64' |
	publish
}

accession () {
	# Assign accession IDs to ingested files.

	# If no arguments are given, list the files that may be
	# processed, then return immediately.
	#
	if [ "$#" -eq 0 ]; then
		get_filepaths verified
		return
	fi

	# We expect exactly two arguments here; one file path and one
	# accession ID.
	#
	if [ "$#" -ne 2 ]; then
		usage_accession >&2
		return 1
	fi

	# Get the message that we want from the "verified" queue (there
	# will be at most one message as they are deduplicated based on
	# the file path, and we're only querying using a single file
	# path), then rewrite them into ingest messages and publish
	# them.
	#
	get_messages verified "$1" |
	jq -r -R --arg accession_id "$2" '@base64d | fromjson |
		.payload |= (
			@base64d | fromjson |
			.type = "accession" |
			.accession_id = $accession_id |
			del(.filesize,.operation) |
			tojson | @base64
		) |
		.routing_key = "accessionIDs" |
		del(.payload_bytes) |
		@base64' |
	publish
}

dataset () {
	# Collect file paths into datasets.

	# If no arguments are given, list the files that may be
	# processed, then return immediately.
	#
	if [ "$#" -eq 0 ]; then
		get_filepaths completed
		return
	fi
	:
}

usage () {
	case ${1-} in
		upload|ingest|accession|dataset)
			"usage_$1"
			;;
		"")
			usage_general
			;;
		*)
			usage_general >&2
			return 1
	esac
}

usage_general () {
cat <<-USAGE_GENERAL
	General synopsis:
	    $myself [GLOBAL OPTIONS] [help] {upload|ingest|accession|dataset} [ARGUMENTS]

	Global options:
	    --sda-config pathname	SDA S3 configuration file	Default: $sda_config
	    --sda-key pathname		SDA CRYPT4GH public key file	Default: $sda_key

	Specific synopsis:
	    $myself help

	    $myself [...] upload pathname [pathname...]
	    $myself help upload

	    $myself [...] ingest pathname [pathname...]
	    $myself [...] ingest
	    $myself help ingest

	    $myself [...] accession pathname accessionID
	    $myself [...] accession
	    $myself help accession

	    $myself [...] dataset [--add] datasetID accessionID [accessionID...]
	    $myself [...] dataset [--add] datasetID pathname [pathname...]
	    $myself [...] dataset datasetID
	    $myself help dataset

	USAGE_GENERAL
}

# Handle global options.
while true; do
	case ${1-} in
		--sda-config)
			sda_config=$2
			;;
		--sda-key)
			sda_key=$2
			;;
		*)
			break
	esac
	shift 2
done

# Handle sub-comands.
case ${1-} in
	upload|ingest|accession|dataset)
		"$@"
		;;
	help)
		shift
		usage "$@"
		;;
	*)
		usage
		exit 1
esac
